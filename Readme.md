## I. Dataset Overview

The LLMdetect dataset focuses on the detection of content generated by large language models, aiming to assist researchers and developers in evaluating and optimizing the quality and compliance of the content generated by large language models. The data sources are diverse, covering public texts such as news, social media, academic papers, and forum discussions, as well as content generated through simulated interactions between users and large language models, comprehensively reflecting the output of large language models in different scenarios.

## II. Data Content

1. **Data Composition**: The dataset contains 29164 samples, and each sample consists of three parts: the input text for the large language model, the output text generated by the model, and the manually annotated detection results.

1. **Data Annotation**: The annotation work is carried out by professional NLP researchers and language experts. The annotation is based on clear detection criteria, covering the authenticity, logic, relevance, and compliance of the generated content (such as whether it contains sensitive information or violates ethical norms). The annotation process undergoes multiple rounds of cross - review and calibration to ensure the accuracy and consistency of the annotations, and the inter - annotator agreement reaches over 90%.

## III. Dataset Usage Instructions

1. **Data Format**: The dataset is stored in CSV format, and the file name is LLMdetect_dataset.csv. The file contains three columns, namely input_text (input text for the large language model), generated_text (output text generated by the model), and detection_result (detection result). The detection results are presented as categorical labels, such as "Compliant", "Non - compliant (Contains Sensitive Information)", "Non - compliant (Logical Error)", etc.

1. **Data Loading**: The data can be easily loaded using the pandas library in Python. The sample code is as follows:

```python
import pandas as pd

data = pd.read_csv('LLMdetect_dataset.csv')
print(data.head())
```

1. **Data Preprocessing Suggestions**: Before using the dataset, it is recommended to clean the text data by removing special characters, HTML tags, etc. For the annotation results, label encoding can be carried out according to specific tasks. For example, one - hot encoding can be used to convert multi - class labels into a format suitable for model input. The following is a simple text cleaning example:

```python
import re

def clean_text(text):
    clean_text = re.sub(r'[^\w\s]', '', text)
    return clean_text

data['input_text'] = data['input_text'].apply(clean_text)
data['generated_text'] = data['generated_text'].apply(clean_text)
```

## IV. Dataset License and Usage Rights

1. **License Agreement**: The LLMdetect dataset is released under the MIT license agreement, allowing users to freely use, copy, modify, merge, publish, distribute, sublicense, and sell the dataset.

1. **Usage Rights Description**:

- - **Public Use**: It can be used free of charge for academic research and educational purposes. When using it in academic papers and research reports, this dataset should be mentioned in the acknowledgments section, and the source of the dataset should be indicated in the references.

- - **Commercial Use**: Enterprises and commercial institutions can use this dataset for commercial product development, service optimization, and other commercial purposes. In the relevant documents of products or services, it is necessary to clearly state the use of this dataset and the MIT license agreement followed.

1. **Restriction Clauses**: Users are not allowed to use the dataset for any illegal activities or behaviors that violate the intellectual property rights, privacy, and other rights and interests of others. Malicious tampering and redistribution of the dataset are prohibited to maintain the originality and integrity of the dataset. If legal disputes arise due to the use of this dataset, the user shall bear the legal responsibilities on their own.

## V. Citation Suggestions

If the LLMdetect dataset is used in research and development, it is recommended to cite it in the following format in relevant achievements:

For example: wpc666. (2025). LLMdetect Dataset. [https://github.com/wpc666/LLMdetect - dataset]0

## VI. Dataset Update and Support

1. **Update Frequency**: The dataset is planned to be updated once a year, incorporating new samples generated by large language models and optimizing the annotation quality to adapt to the continuously evolving large language model technologies and research needs.

1. **Obtaining Updates**: Users can obtain the latest version in the official GitHub repository of the dataset. Each update will provide a detailed update log, explaining the updated content and usage precautions.

1. **Support and Feedback**: If you encounter problems during use, or have improvement suggestions or cooperation intentions, you can contact us through the following methods:

- - **Email**: [Specific Email Address]

- - **GitHub Issues**: Submit your questions or suggestions in the "Issues" section of the dataset's GitHub repository, and we will reply and handle them in a timely manner.